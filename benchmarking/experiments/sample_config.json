{
    "providers": [
       "vLLM", "Azure", "AWSBedrock", "TogetherAI"
    ],
    "models": [
        "common-model-small"
    ],
    "num_requests": 100,
    "input_tokens": [1000, 10000, 100000],
    "streaming": true,
    "max_output": [100],
    "verbose": true
}